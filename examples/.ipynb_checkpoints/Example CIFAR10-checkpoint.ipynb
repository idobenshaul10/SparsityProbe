{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ido/projects/SparsityProbe\n",
      "/home/ido/projects/SparsityProbe/examples\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import DL_Layer_Analysis\n",
    "%cd examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing $\\alpha$-Scores on CIFAR10 Dataset\n",
    "In this example, we will show how to compute the $\\alpha$-scores on a trained CIFAR10 network. \n",
    "We use a Resnet18 trained on CIFAR10. \n",
    "Pretrained Resnet18 taken from https://github.com/huyvnphan/PyTorch_CIFAR10 **(Check it out!)**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DL_Layer_Analysis.clustering import *\n",
    "from DL_Layer_Analysis.DL_smoothness import *\n",
    "from utils.utils import *\n",
    "import pickle\n",
    "loaded_example_args = pickle.load(open(os.path.join('cifar10', 'args.p'), \"rb\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading params for Smoothness Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=1024, calc_test=True, checkpoint_path=None, checkpoints_folder='cifar10/outputs', depth=20, env_name='cifar10_env', epsilon_1=0.1, feature_dimension=100000, feature_dimenstion=1000, low_range_epsilon=0.4, output_folder='cifar10/outputs', seed=1079, trees=5, use_clustering=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print saved args'''\n",
    "loaded_example_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''init number of trees, epsilons, and dim reduction threshold'''\n",
    "loaded_example_args.trees = 5\n",
    "loaded_example_args.epsilon_1 = 0.1\n",
    "loaded_example_args.epsilon_2 = 0.4\n",
    "loaded_example_args.seed = 1079\n",
    "loaded_example_args.feature_dimension = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the Loaders, Datasets, and Layers\n",
    "Following the **env_name** arg, the datasets, model, and model layers are loaded. For more on this, check out **environements/cifar10_env.py**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1024, calc_test=True, checkpoint_path=None, checkpoints_folder='cifar10/outputs', depth=20, env_name='cifar10_env', epsilon_1=0.1, epsilon_2=0.4, feature_dimension=1000, feature_dimenstion=1000, low_range_epsilon=0.4, output_folder='cifar10/outputs', seed=1079, trees=5, use_clustering=False, use_cuda=True)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "'''init the model, along with the test loader, and layers to run analysis on'''\n",
    "args, model, dataset, test_dataset, layers, data_loader =  init_params(args=loaded_example_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cifar10/outputs'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs written to...'''\n",
    "loaded_example_args.output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Sparsity Probe on all given layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:05<00:00,  9.58it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:04,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 layers!\n",
      "LAYER -1, type:layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:05<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing TruncatedSVD, X:torch.Size([50000, 3072]), output_dimension:1000\n",
      "TruncatedSVD took 26.72659730911255\n",
      "X.shape:(50000, 1000), Y shape:(50000, 1)\n",
      "building tree 1 of 5building tree 2 of 5\n",
      "\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5building tree 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   35.8s remaining:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   36.5s finished\n",
      "100%|██████████| 170/170 [00:00<00:00, 672.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHA for LAYER -1 is 0.15076959292991607\n",
      "Fitting k means with k=10\n",
      "START clustering statistics\n",
      "DONE clustering statistics\n",
      "adj_rand:0.04063624023526627\n",
      "MI_score:0.07697876636894073\n",
      "homogeneity_score:0.07673375333637594\n",
      "completeness:0.07788690615803691\n",
      "FMI:0.13971997823187632\n",
      "Fitting umap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting umap\n",
      "layers: 4 2 1\n",
      "LAYER 0, type:layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:07<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing TruncatedSVD, X:(50000, 16384), output_dimension:1000\n"
     ]
    }
   ],
   "source": [
    "'''run sparsity analysis algorithm with given arguments'''\n",
    "# only_umap used when we only want the visualization\n",
    "args.only_umap = False\n",
    "# When we want to comapre to clustering metrics, use args.use_clustering = True\n",
    "args.use_clustering = True\n",
    "# Run sparsity on the CIFAR10 pretrained example\n",
    "sparsity_run_output = run_smoothness_analysis(args, model, dataset, test_dataset, layers, data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the $\\alpha$-Scores vs. Clustering Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DL_Layer_Analysis.plot_DL_json_results import plot_layers\n",
    "# Plot alpha smoothness through the pochs, and compare to clustering scores\n",
    "plot_layers(args.checkpoints_folder, plot_test=True, add_fill=False, use_clustering=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
